{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# beigeBERT\n",
    "\n",
    "This notebook lets you load and then run the fine-tuned beigeBERT model on texts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading in testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\MCOB PHD 14\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import shutil\n",
    "\n",
    "# Load the sentiment scores CSV\n",
    "excel_path = r\"C:/Users/MCOB PHD 14/Dropbox/Charlie's Dissertation/Beige Books/manual_sentiment.csv\"\n",
    "sentiment_data = pd.read_csv(excel_path)\n",
    "\n",
    "# Define the label function\n",
    "def label_sentiment(score):\n",
    "    if score <= -0.3:\n",
    "        return 0  # Negative\n",
    "    elif score <= 0.2:\n",
    "        return 1  # Mixed\n",
    "    else:\n",
    "        return 2  # Positive\n",
    "\n",
    "# Apply the label function to the sentiment scores\n",
    "sentiment_data['label'] = sentiment_data['human_sentiment'].apply(label_sentiment)\n",
    "\n",
    "# Define path where text files are stored\n",
    "text_files_dir = r\"C:/Users/MCOB PHD 14/Dropbox/Charlie's Dissertation/Beige Books/selected_chunks2\"\n",
    "\n",
    "# Load the text files and create a DataFrame\n",
    "text_data = {}\n",
    "for filename in os.listdir(text_files_dir):\n",
    "    if filename.endswith('.txt'):\n",
    "        file_path = os.path.join(text_files_dir, filename)\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            text_data[filename] = file.read()\n",
    "\n",
    "# Combine text data with sentiment data\n",
    "text_df = pd.DataFrame(list(text_data.items()), columns=['file_names', 'text'])\n",
    "combined_data = pd.merge(sentiment_data, text_df, on='file_names')\n",
    "\n",
    "# Split data into training and testing sets\n",
    "train_data, test_data = train_test_split(combined_data, test_size=0.2, random_state=42, stratify=combined_data['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load beigeBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaForSequenceClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
    "import torch\n",
    "\n",
    "# Define the path where the model and tokenizer are saved\n",
    "saved_model_path = 'C:/Users/MCOB PHD 14/Desktop/bbFinal/Notebooks/RoBERTa_three_validated'\n",
    "\n",
    "# Load the saved tokenizer\n",
    "tokenizer = RobertaTokenizer.from_pretrained(saved_model_path)\n",
    "\n",
    "# Load the saved model\n",
    "model = RobertaForSequenceClassification.from_pretrained(saved_model_path)\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to tokenize and predict sentiment\n",
    "def predict_sentiment_with_status(texts):\n",
    "    predictions = []\n",
    "    total_texts = len(texts)\n",
    "    for idx, text in enumerate(tqdm(texts, desc=\"Predicting Sentiment\", ncols=100)):\n",
    "        # Tokenize the text\n",
    "        inputs = tokenizer(\n",
    "            text,\n",
    "            return_tensors=\"pt\",       # Return as PyTorch tensors\n",
    "            truncation=True,           # Truncate longer sequences\n",
    "            padding='max_length',      # Pad to max length\n",
    "            max_length=512             # Set maximum length\n",
    "        )\n",
    "        \n",
    "        # Perform prediction\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "        \n",
    "        # Get the predicted label\n",
    "        predicted_label = torch.argmax(outputs.logits, dim=1).item()\n",
    "        predictions.append(predicted_label)\n",
    "        \n",
    "        # Print status update for every 10 texts\n",
    "        if (idx + 1) % 10 == 0 or (idx + 1) == total_texts:\n",
    "            print(f\"Processed {idx + 1}/{total_texts} texts\")\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting Sentiment:   5%|██                                      | 10/200 [00:04<01:33,  2.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 10/200 texts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting Sentiment:  10%|████                                    | 20/200 [00:09<01:23,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 20/200 texts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting Sentiment:  15%|██████                                  | 30/200 [00:14<01:18,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 30/200 texts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting Sentiment:  20%|████████                                | 40/200 [00:18<01:13,  2.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 40/200 texts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting Sentiment:  25%|██████████                              | 50/200 [00:23<01:10,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 50/200 texts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting Sentiment:  30%|████████████                            | 60/200 [00:28<01:06,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 60/200 texts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting Sentiment:  35%|██████████████                          | 70/200 [00:32<01:00,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 70/200 texts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting Sentiment:  40%|████████████████                        | 80/200 [00:37<00:54,  2.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 80/200 texts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting Sentiment:  45%|██████████████████                      | 90/200 [00:42<00:51,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 90/200 texts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting Sentiment:  50%|███████████████████▌                   | 100/200 [00:46<00:47,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 100/200 texts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting Sentiment:  55%|█████████████████████▍                 | 110/200 [00:51<00:41,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 110/200 texts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting Sentiment:  60%|███████████████████████▍               | 120/200 [00:56<00:35,  2.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 120/200 texts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting Sentiment:  65%|█████████████████████████▎             | 130/200 [01:00<00:32,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 130/200 texts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting Sentiment:  70%|███████████████████████████▎           | 140/200 [01:05<00:27,  2.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 140/200 texts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting Sentiment:  75%|█████████████████████████████▎         | 150/200 [01:09<00:22,  2.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 150/200 texts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting Sentiment:  80%|███████████████████████████████▏       | 160/200 [01:14<00:17,  2.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 160/200 texts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting Sentiment:  85%|█████████████████████████████████▏     | 170/200 [01:18<00:13,  2.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 170/200 texts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting Sentiment:  90%|███████████████████████████████████    | 180/200 [01:23<00:09,  2.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 180/200 texts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting Sentiment:  95%|█████████████████████████████████████  | 190/200 [01:28<00:04,  2.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 190/200 texts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting Sentiment: 100%|███████████████████████████████████████| 200/200 [01:32<00:00,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 200/200 texts\n",
      "                                                  text  predicted_label  \\\n",
      "528  reshaping their job mix . Longer-term , many r...                2   \n",
      "491  December 8 , 1999 The Fifth District economy c...                2   \n",
      "888  over the year in Massachusetts , Boston , and ...                1   \n",
      "899  April 17 , 2019 Summary of Economic Activity S...                2   \n",
      "960  economic conditions visit : https : //www.atla...                1   \n",
      "..                                                 ...              ...   \n",
      "672  , you do n't get the money . '' Looking ahead ...                0   \n",
      "340  split between those expecting the trade balanc...                0   \n",
      "244  activity has been `` unexpectedly quiet '' sin...                1   \n",
      "471  outlook for 1998 , Third District bankers see ...                2   \n",
      "550  for capital investment in the industry , dampe...                1   \n",
      "\n",
      "    predicted_class  \n",
      "528        Positive  \n",
      "491        Positive  \n",
      "888           Mixed  \n",
      "899        Positive  \n",
      "960           Mixed  \n",
      "..              ...  \n",
      "672        Negative  \n",
      "340        Negative  \n",
      "244           Mixed  \n",
      "471        Positive  \n",
      "550           Mixed  \n",
      "\n",
      "[200 rows x 3 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# Apply the prediction function to the 'text' column of test_data DataFrame\n",
    "test_texts = test_data['text'].tolist()  # Convert text column to list\n",
    "test_data['predicted_label'] = predict_sentiment_with_status(test_texts)\n",
    "\n",
    "# Step 4: Map the numerical labels back to the class names (optional)\n",
    "label_map = {0: \"Negative\", 1: \"Mixed\", 2: \"Positive\"}\n",
    "test_data['predicted_class'] = test_data['predicted_label'].map(label_map)\n",
    "\n",
    "# Display the DataFrame with predictions\n",
    "print(test_data[['text', 'predicted_label', 'predicted_class']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Mixed       0.64      0.65      0.65        83\n",
      "    Negative       0.63      0.79      0.70        39\n",
      "    Positive       0.79      0.68      0.73        78\n",
      "\n",
      "    accuracy                           0.69       200\n",
      "   macro avg       0.69      0.71      0.69       200\n",
      "weighted avg       0.70      0.69      0.69       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Convert label in test_data to be Positive, Negative, or Mixed\n",
    "test_data['label'] = test_data['label'].map({0: \"Negative\", 1: \"Mixed\", 2: \"Positive\"})\n",
    "\n",
    "# Display the classification report\n",
    "print(classification_report(test_data['label'], test_data['predicted_class']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename predicted_class as Sentiment_BERT\n",
    "test_data.rename(columns={'predicted_class': 'Sentiment_RoBERTa'}, inplace=True)\n",
    "\n",
    "# Save the test_data DataFrame to a CSV file\n",
    "test_data.to_csv('RoBERTa_predictions.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
